{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1b2f6c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T18:19:38.422689Z",
     "iopub.status.busy": "2025-01-28T18:19:38.422240Z",
     "iopub.status.idle": "2025-01-28T18:19:46.198211Z",
     "shell.execute_reply": "2025-01-28T18:19:46.196421Z"
    },
    "papermill": {
     "duration": 7.782039,
     "end_time": "2025-01-28T18:19:46.200661",
     "exception": false,
     "start_time": "2025-01-28T18:19:38.418622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-2.0.2-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\r\n",
      "Collecting albucore==0.0.23 (from albumentations)\r\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.23->albumentations) (3.11.1)\r\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\r\n",
      "  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Downloading albumentations-2.0.2-py3-none-any.whl (278 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\r\n",
      "Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: simsimd, albucore, albumentations\r\n",
      "  Attempting uninstall: albucore\r\n",
      "    Found existing installation: albucore 0.0.19\r\n",
      "    Uninstalling albucore-0.0.19:\r\n",
      "      Successfully uninstalled albucore-0.0.19\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.4.20\r\n",
      "    Uninstalling albumentations-1.4.20:\r\n",
      "      Successfully uninstalled albumentations-1.4.20\r\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.2 simsimd-6.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974adafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:19:46.211867Z",
     "iopub.status.busy": "2025-01-28T18:19:46.211428Z",
     "iopub.status.idle": "2025-01-28T18:29:21.395456Z",
     "shell.execute_reply": "2025-01-28T18:29:21.394178Z"
    },
    "papermill": {
     "duration": 575.193677,
     "end_time": "2025-01-28T18:29:21.397811",
     "exception": false,
     "start_time": "2025-01-28T18:19:46.204134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Train Dataset...\n",
      "Skipping class 'disgusted' during analysis...\n",
      "Train class counts: {'fearful': 2664, 'angry': 2728, 'neutral': 3597, 'sad': 3079, 'surprised': 2258, 'happy': 5058}, Train max size: 5058\n",
      "Balancing Train Dataset...\n",
      "Augmenting class 'fearful' from 2664 to 5058 images.\n",
      "Class 'fearful' balanced with 5058 images.\n",
      "Skipping class 'disgusted'...\n",
      "Augmenting class 'angry' from 2728 to 5058 images.\n",
      "Class 'angry' balanced with 5058 images.\n",
      "Augmenting class 'neutral' from 3597 to 5058 images.\n",
      "Class 'neutral' balanced with 5058 images.\n",
      "Augmenting class 'sad' from 3079 to 5058 images.\n",
      "Class 'sad' balanced with 5058 images.\n",
      "Augmenting class 'surprised' from 2258 to 5058 images.\n",
      "Class 'surprised' balanced with 5058 images.\n",
      "Class 'happy' balanced with 5058 images.\n",
      "Analyzing Test Dataset...\n",
      "Skipping class 'disgusted' during analysis...\n",
      "Test class counts: {'fearful': 667, 'angry': 683, 'neutral': 900, 'sad': 770, 'surprised': 565, 'happy': 1265}, Test max size: 1265\n",
      "Balancing Test Dataset...\n",
      "Augmenting class 'fearful' from 667 to 1265 images.\n",
      "Class 'fearful' balanced with 1265 images.\n",
      "Skipping class 'disgusted'...\n",
      "Augmenting class 'angry' from 683 to 1265 images.\n",
      "Class 'angry' balanced with 1265 images.\n",
      "Augmenting class 'neutral' from 900 to 1265 images.\n",
      "Class 'neutral' balanced with 1265 images.\n",
      "Augmenting class 'sad' from 770 to 1265 images.\n",
      "Class 'sad' balanced with 1265 images.\n",
      "Augmenting class 'surprised' from 565 to 1265 images.\n",
      "Class 'surprised' balanced with 1265 images.\n",
      "Class 'happy' balanced with 1265 images.\n",
      "Zipping final dataset...\n",
      "Creating ZIP file at /kaggle/working/final_balanced_dataset.zip...\n",
      "ZIP file created: /kaggle/working/final_balanced_dataset.zip\n",
      "Dataset preparation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from albumentations import (\n",
    "    RandomBrightnessContrast,\n",
    "    GaussianBlur,\n",
    "    Affine,\n",
    "    HueSaturationValue,\n",
    "    Compose\n",
    ")\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "log_file = \"/kaggle/working/dataset_preparation.log\"\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    filemode='w',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "def log_and_print(message, level=logging.INFO):\n",
    "    \"\"\"Logs and prints a message.\"\"\"\n",
    "    logging.log(level, message)\n",
    "    print(message)\n",
    "\n",
    "# Augmentation Pipeline\n",
    "augmentation_pipeline = Compose([\n",
    "    RandomBrightnessContrast(p=0.5),\n",
    "    GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "    Affine(scale=(0.95, 1.05), translate_percent=(0.05, 0.05), rotate=0, p=0.7),\n",
    "    HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5)\n",
    "])\n",
    "\n",
    "def augment_image(image_path):\n",
    "    \"\"\"Apply augmentation to a single image and return the augmented image.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "    augmented = augmentation_pipeline(image=image_np)\n",
    "    return Image.fromarray(augmented[\"image\"])\n",
    "\n",
    "# Analyze dataset to find class sizes and the largest class size for the given dataset\n",
    "def analyze_dataset(dataset_dir):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        if class_name.lower() == \"disgusted\":  # Skip the 'disgusted' class\n",
    "            log_and_print(f\"Skipping class '{class_name}' during analysis...\")\n",
    "            continue\n",
    "\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_counts[class_name] = len([f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    max_class_size = max(class_counts.values(), default=0)\n",
    "    return class_counts, max_class_size\n",
    "\n",
    "# Balance dataset by augmenting images\n",
    "def balance_dataset(input_dir, output_dir, max_class_size):\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        if class_name.lower() == \"disgusted\":  # Skip the 'disgusted' class\n",
    "            log_and_print(f\"Skipping class '{class_name}'...\")\n",
    "            continue\n",
    "\n",
    "        class_dir = os.path.join(input_dir, class_name)\n",
    "        output_class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.isdir(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "            num_images = len(images)\n",
    "\n",
    "            # Copy existing images\n",
    "            for img_name in images:\n",
    "                shutil.copy(os.path.join(class_dir, img_name), os.path.join(output_class_dir, img_name))\n",
    "\n",
    "            # Augment images to reach the max_class_size\n",
    "            if num_images < max_class_size:\n",
    "                log_and_print(f\"Augmenting class '{class_name}' from {num_images} to {max_class_size} images.\")\n",
    "                while len(os.listdir(output_class_dir)) < max_class_size:\n",
    "                    for img_name in images:\n",
    "                        if len(os.listdir(output_class_dir)) >= max_class_size:\n",
    "                            break\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        augmented_image = augment_image(img_path)\n",
    "                        augmented_img_name = f\"aug_{len(os.listdir(output_class_dir))}_{img_name}\"\n",
    "                        augmented_image.save(os.path.join(output_class_dir, augmented_img_name))\n",
    "\n",
    "            log_and_print(f\"Class '{class_name}' balanced with {len(os.listdir(output_class_dir))} images.\")\n",
    "\n",
    "# Compress final dataset\n",
    "def create_zip(output_dir, zip_path):\n",
    "    log_and_print(f\"Creating ZIP file at {zip_path}...\")\n",
    "    with ZipFile(zip_path, 'w') as zipf:\n",
    "        for root, _, files in os.walk(output_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, output_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "    log_and_print(f\"ZIP file created: {zip_path}\")\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    INPUT_DIR = \"/kaggle/input/fer-data\"\n",
    "    OUTPUT_DIR = \"/kaggle/working/final_balanced_dataset\"\n",
    "    ZIP_FILE = \"/kaggle/working/final_balanced_dataset.zip\"\n",
    "\n",
    "    # Analyze Train Dataset\n",
    "    log_and_print(\"Analyzing Train Dataset...\")\n",
    "    train_counts, train_max_size = analyze_dataset(os.path.join(INPUT_DIR, \"train\"))\n",
    "    log_and_print(f\"Train class counts: {train_counts}, Train max size: {train_max_size}\")\n",
    "\n",
    "    # Balance Train Dataset\n",
    "    log_and_print(\"Balancing Train Dataset...\")\n",
    "    balance_dataset(os.path.join(INPUT_DIR, \"train\"), os.path.join(OUTPUT_DIR, \"train\"), train_max_size)\n",
    "\n",
    "    # Analyze Test Dataset\n",
    "    log_and_print(\"Analyzing Test Dataset...\")\n",
    "    test_counts, test_max_size = analyze_dataset(os.path.join(INPUT_DIR, \"test\"))\n",
    "    log_and_print(f\"Test class counts: {test_counts}, Test max size: {test_max_size}\")\n",
    "\n",
    "    # Balance Test Dataset\n",
    "    log_and_print(\"Balancing Test Dataset...\")\n",
    "    balance_dataset(os.path.join(INPUT_DIR, \"test\"), os.path.join(OUTPUT_DIR, \"test\"), test_max_size)\n",
    "\n",
    "    # Create ZIP file\n",
    "    log_and_print(\"Zipping final dataset...\")\n",
    "    create_zip(OUTPUT_DIR, ZIP_FILE)\n",
    "\n",
    "    log_and_print(\"Dataset preparation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6544992,
     "sourceId": 10576374,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6546039,
     "sourceId": 10577842,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6562955,
     "sourceId": 10602537,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 587.348958,
   "end_time": "2025-01-28T18:29:23.031859",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-28T18:19:35.682901",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
