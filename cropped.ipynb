{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install facenet-pytorch\n!pip install torch torchvision\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall pillow -y\n!pip install pillow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T06:50:58.481664Z","iopub.execute_input":"2025-01-25T06:50:58.481974Z","iopub.status.idle":"2025-01-25T06:51:06.517252Z","shell.execute_reply.started":"2025-01-25T06:50:58.481947Z","shell.execute_reply":"2025-01-25T06:51:06.515893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom zipfile import ZipFile\n\n# Configuration\nDATASET_DIR = \"/kaggle/working/cropped_dataset\"  # Path to the preprocessed dataset\nOUTPUT_DIR = \"/kaggle/working/shuffled_dataset\"  # Path to save the shuffled dataset\nZIP_FILE = \"/kaggle/working/shuffled_dataset.zip\"  # Path to save the zipped dataset\nTRAIN_RATIO = 0.8  # 80% for training, 20% for testing\n\ndef shuffle_and_split_dataset(dataset_dir, output_dir, zip_file, train_ratio=0.8):\n    \"\"\"\n    Shuffle and re-split the dataset into Train and Test sets, and save as a .zip file.\n\n    Args:\n        dataset_dir (str): Path to the input dataset.\n        output_dir (str): Path to save the shuffled dataset.\n        zip_file (str): Path to save the zipped dataset.\n        train_ratio (float): Proportion of data to use for training.\n\n    Returns:\n        None\n    \"\"\"\n    train_dir = os.path.join(output_dir, \"Train\")\n    test_dir = os.path.join(output_dir, \"Test\")\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)\n\n    # Iterate through classes\n    class_dirs = [os.path.join(dataset_dir, d) for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n    for class_dir in class_dirs:\n        class_name = os.path.basename(class_dir)\n        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n\n        # Shuffle the images\n        random.shuffle(images)\n\n        # Calculate split index\n        split_index = int(len(images) * train_ratio)\n\n        # Split images into Train and Test\n        train_images = images[:split_index]\n        test_images = images[split_index:]\n\n        # Create class subdirectories in Train and Test folders\n        train_class_dir = os.path.join(train_dir, class_name)\n        test_class_dir = os.path.join(test_dir, class_name)\n        os.makedirs(train_class_dir, exist_ok=True)\n        os.makedirs(test_class_dir, exist_ok=True)\n\n        # Copy images to Train and Test directories\n        for img_name in train_images:\n            src_path = os.path.join(class_dir, img_name)\n            dest_path = os.path.join(train_class_dir, img_name)\n            shutil.copy(src_path, dest_path)\n\n        for img_name in test_images:\n            src_path = os.path.join(class_dir, img_name)\n            dest_path = os.path.join(test_class_dir, img_name)\n            shutil.copy(src_path, dest_path)\n\n        print(f\"Class '{class_name}': {len(train_images)} images in Train, {len(test_images)} images in Test.\")\n\n    # Create a ZIP archive of the shuffled dataset\n    print(f\"Creating ZIP file at {zip_file}...\")\n    with ZipFile(zip_file, 'w') as zipf:\n        for root, dirs, files in os.walk(output_dir):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, output_dir)  # Preserve folder structure in the ZIP\n                zipf.write(file_path, arcname)\n    print(f\"ZIP file created at {zip_file}\")\n\n# Run the function\nshuffle_and_split_dataset(DATASET_DIR, OUTPUT_DIR, ZIP_FILE, TRAIN_RATIO)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}