{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b96136",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T16:01:29.499552Z",
     "iopub.status.busy": "2025-01-28T16:01:29.499046Z",
     "iopub.status.idle": "2025-01-28T16:01:37.436484Z",
     "shell.execute_reply": "2025-01-28T16:01:37.434814Z"
    },
    "papermill": {
     "duration": 7.944145,
     "end_time": "2025-01-28T16:01:37.438930",
     "exception": false,
     "start_time": "2025-01-28T16:01:29.494785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-2.0.2-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\r\n",
      "Collecting albucore==0.0.23 (from albumentations)\r\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.23->albumentations) (3.11.1)\r\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\r\n",
      "  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Downloading albumentations-2.0.2-py3-none-any.whl (278 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\r\n",
      "Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: simsimd, albucore, albumentations\r\n",
      "  Attempting uninstall: albucore\r\n",
      "    Found existing installation: albucore 0.0.19\r\n",
      "    Uninstalling albucore-0.0.19:\r\n",
      "      Successfully uninstalled albucore-0.0.19\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.4.20\r\n",
      "    Uninstalling albumentations-1.4.20:\r\n",
      "      Successfully uninstalled albumentations-1.4.20\r\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.2 simsimd-6.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8727f5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T16:01:37.446909Z",
     "iopub.status.busy": "2025-01-28T16:01:37.446498Z",
     "iopub.status.idle": "2025-01-28T16:47:33.247811Z",
     "shell.execute_reply": "2025-01-28T16:47:33.246056Z"
    },
    "papermill": {
     "duration": 2755.86076,
     "end_time": "2025-01-28T16:47:33.303218",
     "exception": false,
     "start_time": "2025-01-28T16:01:37.442458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Train Dataset...\n",
      "Train class counts: {'fearful': 2664, 'disgusted': 284, 'angry': 2728, 'neutral': 3597, 'sad': 3079, 'surprised': 2258, 'happy': 5058}, Max size: 7215\n",
      "Balancing Train Dataset...\n",
      "Augmenting class 'fearful' from 2664 to 7215 images.\n",
      "Class 'fearful' balanced with 7215 images.\n",
      "Augmenting class 'disgusted' from 284 to 7215 images.\n",
      "Class 'disgusted' balanced with 7215 images.\n",
      "Augmenting class 'angry' from 2728 to 7215 images.\n",
      "Class 'angry' balanced with 7215 images.\n",
      "Augmenting class 'neutral' from 3597 to 7215 images.\n",
      "Class 'neutral' balanced with 7215 images.\n",
      "Augmenting class 'sad' from 3079 to 7215 images.\n",
      "Class 'sad' balanced with 7215 images.\n",
      "Augmenting class 'surprised' from 2258 to 7215 images.\n",
      "Class 'surprised' balanced with 7215 images.\n",
      "Augmenting class 'happy' from 5058 to 7215 images.\n",
      "Class 'happy' balanced with 7215 images.\n",
      "Analyzing Test Dataset...\n",
      "Test class counts: {'fearful': 667, 'disgusted': 71, 'angry': 683, 'neutral': 900, 'sad': 770, 'surprised': 565, 'happy': 1265}, Max size: 7215\n",
      "Balancing Test Dataset...\n",
      "Augmenting class 'fearful' from 667 to 7215 images.\n",
      "Class 'fearful' balanced with 7215 images.\n",
      "Augmenting class 'disgusted' from 71 to 7215 images.\n",
      "Class 'disgusted' balanced with 7215 images.\n",
      "Augmenting class 'angry' from 683 to 7215 images.\n",
      "Class 'angry' balanced with 7215 images.\n",
      "Augmenting class 'neutral' from 900 to 7215 images.\n",
      "Class 'neutral' balanced with 7215 images.\n",
      "Augmenting class 'sad' from 770 to 7215 images.\n",
      "Class 'sad' balanced with 7215 images.\n",
      "Augmenting class 'surprised' from 565 to 7215 images.\n",
      "Class 'surprised' balanced with 7215 images.\n",
      "Augmenting class 'happy' from 1265 to 7215 images.\n",
      "Class 'happy' balanced with 7215 images.\n",
      "Zipping final dataset...\n",
      "Creating ZIP file at /kaggle/working/final_balanced_dataset.zip...\n",
      "ZIP file created: /kaggle/working/final_balanced_dataset.zip\n",
      "Dataset preparation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from albumentations import (\n",
    "    RandomBrightnessContrast,\n",
    "    GaussianBlur,\n",
    "    Affine,\n",
    "    HueSaturationValue,\n",
    "    Compose\n",
    ")\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "log_file = \"/kaggle/working/dataset_preparation.log\"\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    filemode='w',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "def log_and_print(message, level=logging.INFO):\n",
    "    \"\"\"Logs and prints a message.\"\"\"\n",
    "    logging.log(level, message)\n",
    "    print(message)\n",
    "\n",
    "# Augmentation Pipeline\n",
    "augmentation_pipeline = Compose([\n",
    "    RandomBrightnessContrast(p=0.5),\n",
    "    GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "    Affine(scale=(0.95, 1.05), translate_percent=(0.05, 0.05), rotate=0, p=0.7),\n",
    "    HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5)\n",
    "])\n",
    "\n",
    "# Analyze dataset to find class sizes and the largest class\n",
    "def analyze_dataset(dataset_dir):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_counts[class_name] = len([f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    max_class_size = 7215  # Target size for all classes\n",
    "    return class_counts, max_class_size\n",
    "\n",
    "# Perform image augmentation\n",
    "def augment_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = ImageOps.exif_transpose(image)  # Correct orientation\n",
    "    image_np = np.array(image)\n",
    "    augmented = augmentation_pipeline(image=image_np)\n",
    "    return Image.fromarray(augmented['image'])\n",
    "\n",
    "# Balance dataset by augmenting images\n",
    "def balance_dataset(input_dir, output_dir, max_class_size):\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_dir = os.path.join(input_dir, class_name)\n",
    "        output_class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.isdir(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "            num_images = len(images)\n",
    "\n",
    "            # Copy existing images\n",
    "            for img_name in images:\n",
    "                shutil.copy(os.path.join(class_dir, img_name), os.path.join(output_class_dir, img_name))\n",
    "\n",
    "            # Augment images to reach the max_class_size\n",
    "            if num_images < max_class_size:\n",
    "                log_and_print(f\"Augmenting class '{class_name}' from {num_images} to {max_class_size} images.\")\n",
    "                while len(os.listdir(output_class_dir)) < max_class_size:\n",
    "                    for img_name in images:\n",
    "                        if len(os.listdir(output_class_dir)) >= max_class_size:\n",
    "                            break\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        augmented_image = augment_image(img_path)\n",
    "                        augmented_img_name = f\"aug_{len(os.listdir(output_class_dir))}_{img_name}\"\n",
    "                        augmented_image.save(os.path.join(output_class_dir, augmented_img_name))\n",
    "\n",
    "            log_and_print(f\"Class '{class_name}' balanced with {len(os.listdir(output_class_dir))} images.\")\n",
    "\n",
    "# Compress final dataset\n",
    "def create_zip(output_dir, zip_path):\n",
    "    log_and_print(f\"Creating ZIP file at {zip_path}...\")\n",
    "    with ZipFile(zip_path, 'w') as zipf:\n",
    "        for root, _, files in os.walk(output_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, output_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "    log_and_print(f\"ZIP file created: {zip_path}\")\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    INPUT_DIR = \"/kaggle/input/fer-data\"\n",
    "    OUTPUT_DIR = \"/kaggle/working/final_balanced_dataset\"\n",
    "    ZIP_FILE = \"/kaggle/working/final_balanced_dataset.zip\"\n",
    "\n",
    "    # Train dataset\n",
    "    log_and_print(\"Analyzing Train Dataset...\")\n",
    "    train_counts, train_max_size = analyze_dataset(os.path.join(INPUT_DIR, \"train\"))\n",
    "    log_and_print(f\"Train class counts: {train_counts}, Max size: {train_max_size}\")\n",
    "\n",
    "    log_and_print(\"Balancing Train Dataset...\")\n",
    "    balance_dataset(os.path.join(INPUT_DIR, \"train\"), os.path.join(OUTPUT_DIR, \"train\"), train_max_size)\n",
    "\n",
    "    # Test dataset\n",
    "    log_and_print(\"Analyzing Test Dataset...\")\n",
    "    test_counts, test_max_size = analyze_dataset(os.path.join(INPUT_DIR, \"test\"))\n",
    "    log_and_print(f\"Test class counts: {test_counts}, Max size: {test_max_size}\")\n",
    "\n",
    "    log_and_print(\"Balancing Test Dataset...\")\n",
    "    balance_dataset(os.path.join(INPUT_DIR, \"test\"), os.path.join(OUTPUT_DIR, \"test\"), test_max_size)\n",
    "\n",
    "    # Create ZIP file\n",
    "    log_and_print(\"Zipping final dataset...\")\n",
    "    create_zip(OUTPUT_DIR, ZIP_FILE)\n",
    "\n",
    "    log_and_print(\"Dataset preparation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6544992,
     "sourceId": 10576374,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6546039,
     "sourceId": 10577842,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6562955,
     "sourceId": 10602537,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2769.243175,
   "end_time": "2025-01-28T16:47:35.885547",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-28T16:01:26.642372",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
