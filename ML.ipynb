{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10579712,"sourceType":"datasetVersion","datasetId":6547346}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nfrom zipfile import ZipFile\n\n# Define input and output paths\ninput_path = '/kaggle/input/final-dataset'\noutput_path = '/kaggle/working/combined-dataset'\nzip_output_path = '/kaggle/working/combined-dataset.zip'\n\n# Create output folders if they don't exist\nos.makedirs(output_path, exist_ok=True)\n\n# Define Train and Test folders\nfolders = ['Train', 'Test']\n\n# Function to combine datasets based on classes\ndef combine_datasets(input_path, output_path, folders):\n    for folder in folders:\n        input_folder_path = os.path.join(input_path, folder)\n        output_folder_path = os.path.join(output_path, folder)\n\n        # Ensure the output folder exists\n        os.makedirs(output_folder_path, exist_ok=True)\n\n        # Iterate through class folders in the Train/Test folder\n        for class_folder in os.listdir(input_folder_path):\n            class_input_path = os.path.join(input_folder_path, class_folder)\n\n            # Ensure the class folder exists in the output\n            class_output_path = os.path.join(output_folder_path, class_folder)\n            os.makedirs(class_output_path, exist_ok=True)\n\n            # Copy all files from the input class folder to the output class folder\n            for file in os.listdir(class_input_path):\n                src_file_path = os.path.join(class_input_path, file)\n                dst_file_path = os.path.join(class_output_path, file)\n\n                # Copy file if it doesn't already exist or overwrite if required\n                shutil.copy(src_file_path, dst_file_path)\n\n# Combine datasets\ncombine_datasets(input_path, output_path, folders)\n\n# Create a ZIP file of the combined dataset\nwith ZipFile(zip_output_path, 'w') as zipf:\n    for root, dirs, files in os.walk(output_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, output_path)  # Relative path for ZIP\n            zipf.write(file_path, arcname)\n\nprint(f\"Combined dataset saved as ZIP at: {zip_output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}